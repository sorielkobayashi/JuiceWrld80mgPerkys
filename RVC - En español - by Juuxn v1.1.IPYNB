{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1tzqQLZbCAMTOwG2yaWQVPI_hG0StUPpu","timestamp":1683780496149},{"file_id":"1mrHh7uqWp43F5jJp6MOXPvumMho3Lj4X","timestamp":1683589475562},{"file_id":"1iHumZNFgvIHqX4VCJh4dcXkdzECPE8fO","timestamp":1682377764710},{"file_id":"1DunK_g2uq8dTA13MtA_RXF4uG4Ph_uqg","timestamp":1682320070478},{"file_id":"1jrsoiIQiJcbpgQPPFAHbbYo8-N88xIME","timestamp":1682284944875},{"file_id":"https://github.com/liujing04/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb","timestamp":1682115412258}],"collapsed_sections":["p9SHghdUw2O_"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["[Tutorial para cuaderno tradicional](https://www.youtube.com/embed/R8-PivPpv8o)\n","</br>[Transefir archivos de mega a drive](https://colab.research.google.com/drive/1utTesfmBv-uQ8Upa7TEVpM57kmcq9YN6?usp=sharing):\n","</br>\n","Codigo para quedarse afk durante el entrenamiento (máximo de 6 horas, pero puede variar dependiendo del uso que se le ha dado a la cuenta)\n","```js\n","function ClickConnect(){\n","console.log(\"Working\"); \n","document.querySelector(\"colab-toolbar-button#connect\").click() \n","}\n","setInterval(ClickConnect,60000)\n","````\n","**Para inferencia:**\n","1. Instala las dependencias con el check de \"solo inferencia\" activado\n","2. Descarga el modelo que vas a usar con el paso 3 o 3b si la url ya llegó a su limite de uso.\n","3. Ejecuta la interfaz de gradio con todos los check desactivados.\n","**Para entrenamiento:**\n","1. Instala las dependencias con el check de \"solo inferencia\" desactivado\n","2. Sube tu dataset a drive, en el folder \"dataset\" y luego seleccionalo en el paso 2 o descarga un dataset desde un enlace con el paso 2b\n","3. Si vas a reentrenar, carga tu modelo con el paso 3 o 3b\n","4. Ejecuta la interfaz de gradio con el check de \"modo_entrenamiento\" activado. Lo demás es opcional.\n","5. Guarda tu modelo indicando el nombre y el tipo de guardado."],"metadata":{"id":"Xtm7dWT3Bj83"}},{"cell_type":"code","source":["#@title <font color='#018ada'>Paso 1. Instalar dependencias</font> <font color=\"red\">(inferencia/entrenamiento)</font>\n","solo_inferencia = False #@param{type:'boolean'}\n","\n","print('Iniciando...')\n","!pip install termcolor -q --root-user-action=ignore 2>/dev/null\n","!pip install colab-env --upgrade > /dev/null 2>&1 \n","!apt-get -y install build-essential python3-dev ffmpeg > /dev/null 2>&1 \n","!pip3 install --upgrade setuptools wheel -q --root-user-action=ignore 2>/dev/null\n","!pip3 install --upgrade pip -q --root-user-action=ignore 2>/dev/null\n","!pip3 install faiss-gpu fairseq gradio ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2 -q --root-user-action=ignore 2>/dev/null\n","!apt -y install -qq aria2 > /dev/null 2>&1\n","!pip install mega.py --quiet -q --root-user-action=ignore 2>/dev/null\n","!pip install gdown --quiet -q --root-user-action=ignore 2>/dev/null\n","import ipywidgets as widgets\n","from IPython.display import clear_output\n","import os, shutil\n","from termcolor import cprint\n","\n","success=widgets.Button(description=\"\\u2714 Complettado\",disabled=True, button_style=\"success\")\n","\n","if os.path.exists(\"/content/RVC\"):\n","  shutil.rmtree(\"/content/RVC\")\n","  \n","print(\"Descargando repositorio...\")\n","\n","%cd /content/\n","!git clone https://github.com/xJuuzouYTx/RVC.git > /dev/null 2>&1\n","%cd /content/RVC\n","!git checkout 50b5114bd5b2602d2ed151fcb5cc82551b8ac77e\n","!mkdir -p pretrained uvr5_weights\n","!git pull\n","\n","print(\"Descargando modelos base...\")\n","\n","if not solo_inferencia:\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d /content/RVC/pretrained -o D32k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d /content/RVC/pretrained -o D40k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d /content/RVC/pretrained -o D48k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d /content/RVC/pretrained -o G32k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d /content/RVC/pretrained -o G40k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d /content/RVC/pretrained -o G48k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d /content/RVC/pretrained -o f0D32k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d /content/RVC/pretrained -o f0D40k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d /content/RVC/pretrained -o f0D48k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d /content/RVC/pretrained -o f0G32k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d /content/RVC/pretrained -o f0G40k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d /content/RVC/pretrained -o f0G48k.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d /content/RVC/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth > /dev/null 2>&1\n","  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d /content/RVC/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth > /dev/null 2>&1\n","\n","  cprint(\"Conectando con google drive...\",\"blue\")\n","\n","  from google.colab import drive\n","  drive.mount('/content/drive', force_remount=True)\n","  !mkdir -p /content/drive/MyDrive/RVC\n","  !mkdir -p /content/drive/MyDrive/dataset\n","  !mkdir -p /content/EasyDataset\n","\n","!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -d /content/RVC -o hubert_base.pt > /dev/null 2>&1\n","!rm -r /content/RVC/easy-infer.py\n","\n","shutil.move(\"/content/RVC/colab/easy-infer.py\",\"/content/RVC/easy-infer.py\")\n","\n","clear_output()\n","display(success)\n","print(\"Carga tu dataset en la carpeta 'dataset' de tu drive\")"],"metadata":{"id":"wjddIFr1oS3W","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color='#018ada'>Paso 2. Cargar dataset</font> <font color=\"red\">(entrenamiento)</font>\n","#@markdown Sube tus dataset a la carpeta \"dataset\" de tu unidad drive y luego ejecuta\n","from ipywidgets import HBox\n","\n","# Crear lista de modelos\n","models = []\n","models_dropdown = widgets.Dropdown(options=models)\n","\n","def update_dataset_list(e):\n","  clear_output()\n","  dataset_list = []\n","  dataset_dir = os.listdir('/content/drive/MyDrive/dataset')\n","  for file in dataset_dir:\n","    if file.endswith('.zip'):\n","      dataset_list.append(file)\n","  models_dropdown.options = dataset_list\n","  display(models_dropdown)\n","  contenedor = HBox([refresh_dataset_button, load_dataset_button])\n","  display(contenedor)\n","\n","\n","def remove_special_characters(folder_path):\n","    for folder_name in os.listdir(folder_path):\n","        folder_path_old = os.path.join(folder_path, folder_name)\n","        folder_name_new = ''.join(c for c in folder_name if c.isalnum() or c in ['.', '_'])\n","        folder_path_new = os.path.join(folder_path, folder_name_new)\n","        os.rename(folder_path_old, folder_path_new)\n","\n","def load_dataset_clicked(e):\n","  DATASET = models_dropdown.value\n","  \n","  if not DATASET:\n","    assert DATASET, \"No puede estar vacio\"\n","    \n","  dataset_path = '/content/drive/MyDrive/dataset/' + DATASET\n","\n","  if not os.path.exists(dataset_path):\n","    assert os.path.exists(dataset_path), f'No existe {DATASET} en {os.path.dirname(dataset_path)}'\n","  else:\n","    !mkdir -p /content/dataset\n","    !unzip -d /content/dataset -B {dataset_path}\n","    !ls -a /content/dataset/\n","    !rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*\n","\n","    # Eliminar espacios y caracteres especiales en los nombres de las carpetas\n","    remove_special_characters('/content/dataset')\n","\n","    clear_output()\n","    display(success)\n","\n","display(models_dropdown)\n","\n","# Crear botonn de actualizar\n","refresh_dataset_button = widgets.Button(description=\"Actualizar lista\")\n","refresh_dataset_button.on_click(update_dataset_list)\n","# Crear boton de cargar dataset\n","load_dataset_button = widgets.Button(description=\"Cargar dataset\")\n","load_dataset_button.on_click(load_dataset_clicked)\n","\n","contenedor = HBox([refresh_dataset_button, load_dataset_button])\n","display(contenedor)"],"metadata":{"cellView":"form","id":"_ZykC2KmQlmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color='#018ada'>Paso 2b. Descargar dataset desde un url</font> <font color=\"red\">(entrenamiento)</font>\n","import gdown\n","from mega import Mega\n","import unicodedata\n","import ipywidgets as widgets\n","from ipywidgets import HBox\n","import time\n","\n","dataset_success=widgets.Button(description=\"\\u2714 Dataset cargado\",disabled=True, button_style=\"success\")\n","\n","dataset_list = []\n","dataset_input = widgets.Dropdown(\n","    options=dataset_list,\n","    description='Seleccione su dataset:',\n","    value=None,\n","    layout={'width': 'max-content'},\n","    style={'description_width': 'initial'}\n",")\n","\n","url = \"https://drive.google.com/uc?id=1-8LSD5ieLe6MiClmATDE63Jf_ORmM_H2\"#@param {type:'string'}\n","if url != '':\n","  if \"drive.google.com\" in url:\n","    if \"file/d/\" in url:\n","      file_id = url.split(\"file/d/\")[1].split(\"/\")[0]\n","    elif \"id=\" in url:\n","      file_id = url.split(\"id=\")[1].split(\"&\")[0]\n","    else:\n","      print(\"Enlace de Google Drive no válido.\")\n","      file_id = None\n","    if file_id:\n","      %cd /content/drive/MyDrive/dataset\n","      filename = gdown.download(url=f\"https://drive.google.com/uc?id={file_id}\", fuzzy=True)\n","      if not filename:\n","        print(\"Parece que el enlace ha sido demasiado usado, intentando descargar con el método de acceso directo.\")\n","        print(\"Puedes usar el siguiente tutorial para sacarle una copia al archivo original: https://www.youtube.com/watch?v=dwhh8APJCxA\")\n","      \n","      file_path = f\"/content/drive/MyDrive/dataset/{filename}\"\n","      # Normalizar el nombre del archivo\n","      normalized_filename = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode('ascii')\n","      # Eliminar espacios y caracteres especiales\n","      sanitized_filename = ''.join(c for c in normalized_filename if c.isalnum() or c in ['.', '_'])\n","      # Renombrar el archivo\n","      new_filename = os.path.join(f\"/content/drive/MyDrive/dataset\", sanitized_filename)\n","      os.rename(file_path, new_filename)\n","      filename = new_filename\n","        \n","  elif \"mega.nz\" in url:\n","    if \"#!\" in url:\n","      file_id = url.split(\"#!\")[1].split(\"!\")[0]\n","    elif \"file/\" in url:\n","      file_id = url.split(\"file/\")[1].split(\"/\")[0]\n","    else:\n","      print(\"Enlace de Mega no válido.\")\n","      file_id = None\n","    if file_id:\n","      m = Mega()\n","      print(\"Descargando desde mega...\")\n","      file_path = m.download_url(url, \"/content/drive/MyDrive/dataset\")\n","\n","# Crear lista de modelos\n","models = []\n","models_dropdown = widgets.Dropdown(options=models)\n","\n","def update_dataset_list(e):\n","  clear_output()\n","  dataset_list = []\n","  dataset_dir = os.listdir('/content/drive/MyDrive/dataset')\n","  for file in dataset_dir:\n","    if file.endswith('.zip'):\n","      dataset_list.append(file)\n","  models_dropdown.options = dataset_list\n","  display(models_dropdown)\n","  contenedor = HBox([refresh_dataset_button, load_dataset_button])\n","  display(contenedor)\n","\n","\n","def remove_special_characters(folder_path):\n","    for folder_name in os.listdir(folder_path):\n","        folder_path_old = os.path.join(folder_path, folder_name)\n","        folder_name_new = ''.join(c for c in folder_name if c.isalnum() or c in ['.', '_'])\n","        folder_path_new = os.path.join(folder_path, folder_name_new)\n","        os.rename(folder_path_old, folder_path_new)\n","\n","def dataset_button_clicked(b):\n","    DATASET = dataset_input.value\n","    if not DATASET:\n","      print(\"No puede estar vacio\")\n","      return\n","    \n","    dataset_path = '/content/drive/MyDrive/dataset/' + DATASET\n","\n","    if not os.path.exists(dataset_path):\n","      print(f'No existe {DATASET} en {os.path.dirname(dataset_path)}')\n","      return\n","    else:\n","      !mkdir -p /content/dataset\n","      !unzip -d /content/dataset -B {dataset_path}\n","      !ls -a /content/dataset/\n","      !rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*\n","\n","      # Eliminar espacios y caracteres especiales en los nombres de las carpetas\n","      remove_special_characters('/content/dataset')\n","\n","      clear_output()\n","      display(dataset_success)\n","\n","def update_dataset_list_button_clicked(b):\n","  clear_output()\n","  dataset_list = []\n","  dataset_dir = os.listdir('/content/drive/MyDrive/dataset')\n","  for file in dataset_dir:\n","    if file.endswith('.zip'):\n","      dataset_list.append(file)\n","      dataset_input.options = dataset_list\n","  display(dataset_input)\n","  display(contenedor)\n","\n","clear_output()\n","dataset_list = []\n","dataset_dir = os.listdir('/content/drive/MyDrive/dataset')\n","for file in dataset_dir:\n","  if file.endswith('.zip'):\n","    dataset_list.append(file)\n","\n","dataset_input.options = dataset_list\n","display(dataset_input)\n","\n","load_dataset_button = widgets.Button(description=\"Continuar\")\n","load_dataset_button.on_click(dataset_button_clicked)\n","update_dataset_list_button = widgets.Button(description=\"Actualizar\")\n","update_dataset_list_button.on_click(update_dataset_list_button_clicked)\n","contenedor = HBox([update_dataset_list_button, load_dataset_button])\n","display(contenedor)"],"metadata":{"cellView":"form","id":"zo-CuYSttAo9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color=\"#018ada\">Paso 3. Descargar un modelo (Mega/Drive/Huggingface) </font> <font color=\"red\">(inferencia/entrenamiento)</font>\n","import gdown\n","from mega import Mega\n","import urllib.parse\n","import ipywidgets as widgets\n","\n","success=widgets.Button(description=\"\\u2714 Hecho\",disabled=True, button_style=\"success\")\n","\n","url= \"https://drive.google.com/file/d/1-1BIR2UX9OhowhK_kckXUQgnyGyYSwuw/view?usp=sharing\" #@param{type:'string'}\n","\n","zips_path='/content/zips/'\n","!mkdir -p $zips_path\n","\n","downloaded_model = False\n","if url != '':\n","  if \"drive.google.com\" in url:\n","    if \"file/d/\" in url:\n","      file_id = url.split(\"file/d/\")[1].split(\"/\")[0]\n","    elif \"id=\" in url:\n","      file_id = url.split(\"id=\")[1].split(\"&\")[0]\n","    else:\n","      print(\"Enlace de Google Drive no válido.\")\n","      file_id = None\n","    if file_id:\n","      %cd /content/zips\n","      filename = gdown.download(url=f\"https://drive.google.com/uc?id={file_id}\", fuzzy=True)\n","      if not filename:\n","        print(\"Parece que el enlace ha sido demasiado usado, intentando descargar con el método de acceso directo.\")\n","        print(\"Por favor usa el paso 2b o sigue este tutorial para obtener una url nueva: https://www.youtube.com/watch?v=dwhh8APJCxA\")\n","        raise(\"Enlace no valido\")\n","\n","      unzipped_dir = os.path.join('/content/unzips', filename)\n","      downloaded_model = True\n","      \n","  elif \"mega.nz\" in url:\n","    if \"#!\" in url:\n","      file_id = url.split(\"#!\")[1].split(\"!\")[0]\n","    elif \"file/\" in url:\n","      file_id = url.split(\"file/\")[1].split(\"/\")[0]\n","    else:\n","      print(\"Enlace de Mega no válido.\")\n","      file_id = None\n","    if file_id:\n","      m = Mega()\n","      print(\"Descargando desde mega...\")\n","      file_path = m.download_url(url, zips_path)\n","      unzipped_dir = file_path\n","      downloaded_model = True\n","\n","  else:\n","    %cd /content/zips\n","    !wget ${\"'\"+url+\"'\"}\n","    filename = os.path.basename(url.replace(\"%20\",\" \"))\n","    new_filename = filename.replace(\" \",\"_\")\n","    os.rename(f\"/content/zips/{filename}\",f\"/content/zips/{new_filename}\")\n","    unzipped_dir = os.path.join('/content/unzips', new_filename)\n","    downloaded_model = True\n","\n","  # Directorio donde se descomprimió el archivo\n","  MODELNAME = os.path.basename(os.path.normpath(str(unzipped_dir).replace(\".zip\",\"\")))\n","\n","  weights_dir = '/content/RVC/weights'\n","  logs_dir = os.path.join(\"/content/RVC/logs/\", MODELNAME)\n","  if os.path.exists(logs_dir):\n","    # Si el archivo ya existe, eliminarlo\n","    shutil.rmtree(logs_dir)\n","    \n","  if not os.path.exists(weights_dir):\n","    os.mkdir(weights_dir)\n","  \n","  os.mkdir(logs_dir)\n","  \n","  if downloaded_model:\n","    zip_file = os.path.join(zips_path, MODELNAME + \".zip\")\n","    unzipped_dir = os.path.join(\"/content/unzips\", MODELNAME)\n","\n","    # Eliminar el directorio de destino si ya existe\n","    if os.path.exists(unzipped_dir):\n","      shutil.rmtree(unzipped_dir)\n","\n","    # Descomprimir el archivo ZIP utilizando el nombre MODELNAME\n","    shutil.unpack_archive(zip_file, extract_dir=\"/content/unzips/\" +  MODELNAME, format='zip')\n","  else:\n","    raise Exception(\"Error descargando el modelo\")\n","  \n","  logs_folders = ['0_gt_wavs','1_16k_wavs','2a_f0','2b-f0nsf','3_feature256']\n","  \n","  index_file = False\n","  model_file = False\n","  D_file = False\n","  G_file = False\n","  \n","  model_name = MODELNAME\n","   # Mover el archivo D, G y added_*.index\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    for item in files:\n","      item_path = os.path.join(path, item)\n","      if not 'G_' in item and not 'D_' in item and item.endswith('.pth'):\n","        model_file = True\n","        model_name = item.replace(\".pth\",\"\")\n","        shutil.rmtree(logs_dir)\n","        logs_dir = f\"/content/RVC/logs/{model_name}\"\n","        os.mkdir(logs_dir)\n","        if not os.path.exists(weights_dir):\n","          os.mkdir(weights_dir)\n","        if os.path.exists(os.path.join(weights_dir, item)):\n","          os.remove(os.path.join(weights_dir, item))  \n","        if os.path.exists(item_path):\n","          shutil.move(item_path, weights_dir)\n","\n","  # Mover el model.pth y renombrar folder\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    for item in files:\n","      item_path = os.path.join(path, item)\n","      if item.startswith('added_') and item.endswith('.index'):\n","        index_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if 'D_' in item and item.endswith('.pth'):\n","        D_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if 'G_' in item and item.endswith('.pth'):\n","        G_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if item.startswith('total_fea.npy'):\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","          \n","  # Mover todos los folders excepto 'eval'\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    print(subdirs)\n","    for folder in subdirs:\n","      print(folder)\n","      if folder in logs_folders:\n","        item_path = os.path.join(path, folder)\n","        shutil.move(item_path, logs_dir)\n","\n","  #!rm -r /content/RVC/logs/{MODELNAME}\n","  !rm -r /content/unzips/\n","  !rm -r /content/zips/\n","\n","  clear_output()\n","  display(success)\n","\n","  if model_file:\n","    if index_file:\n","      print(\"El modelo funciona para inferencia, y tiene el archivo .index\")\n","    else:\n","      print(\"El modelo funciona para inferencia, pero no tiene el archivo .index\")\n","  if D_file and G_file:\n","    print(\"El modelo puede ser reentrenado.\")\n"],"metadata":{"id":"Mwk7Q0Loqzjx","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color=\"#018ada\">Paso 3b. Cargar modelo desde url muy usada (Permiso de lectura y escritura avanzada en drive - OPCIONAL)</font> <font color=\"red\">(inferencia/entrenamiento)</font>\n","#@markdown **Nota:** Si el modelo pesa más de 2gb puede tardar hasta 5 minutos\n","import os\n","import shutil\n","from google.colab import drive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","from urllib.parse import urlparse, parse_qs, urlunparse\n","import time\n","import ipywidgets as widgets\n","success=widgets.Button(description=\"\\u2714 Hecho\",disabled=True, button_style=\"success\")\n","\n","%cd ~\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","gdrive = GoogleDrive(gauth)\n","\n","def crear_acceso_directo(enlace):\n","        if os.path.exists('/content/drive/MyDrive/temporalmodels'):\n","          shutil.rmtree('/content/drive/MyDrive/temporalmodels')\n","\n","        # Obtiene el ID del archivo desde el enlace\n","        id_archivo = enlace.split('/')[-2]\n","        \n","        # Busca la carpeta \"tempmodel\"\n","        carpeta_models = gdrive.ListFile({'q': \"title='temporalmodels' and mimeType='application/vnd.google-apps.folder' and trashed=false\"}).GetList()\n","        \n","        # Si la carpeta \"temporalmodels\" no existe, la crea\n","        nueva_carpeta = gdrive.CreateFile({\n","            'title': 'temporalmodels',\n","            'mimeType': 'application/vnd.google-apps.folder'\n","        })\n","        nueva_carpeta.Upload()\n","        carpeta_models_id = nueva_carpeta['id']\n","\n","        # Verifica si ya existe un acceso directo con el mismo nombre\n","        acceso_directo_existente = gdrive.ListFile({'q': f\"title='tempmodel' and '{carpeta_models_id}' in parents and mimeType='application/vnd.google-apps.shortcut' and trashed=false\"}).GetList()\n","        \n","        if len(acceso_directo_existente) > 0:\n","            # Si ya existe un acceso directo con el mismo nombre, lo reemplaza\n","            acceso_directo = acceso_directo_existente[0]\n","            acceso_directo['shortcutDetails'] = {'targetId': id_archivo}\n","            acceso_directo.Upload()\n","        else:\n","            # Si no existe un acceso directo con el mismo nombre, lo crea\n","            enlace_simbolico = gdrive.CreateFile({\n","                'mimeType': 'application/vnd.google-apps.shortcut',\n","                'shortcutDetails': {\n","                    'targetId': id_archivo\n","                },\n","                'parents': [{'id': carpeta_models_id}]\n","            })\n","            enlace_simbolico.Upload()\n","            enlace_simbolico.FetchMetadata() \n","\n","def format_google_drive_url(url):\n","    parsed_url = urlparse(url)\n","\n","    # Verificar si la URL ya está en el formato deseado\n","    if '/file/d/' in parsed_url.path and '/view' in parsed_url.path:\n","        return url\n","\n","    # Extraer el ID del archivo\n","    query_params = parse_qs(parsed_url.query)\n","    file_id = query_params.get('id', [''])[0]\n","\n","    # Crear los nuevos componentes de la URL\n","    new_path = f'/file/d/{file_id}/view'\n","    new_query = 'usp=sharing'\n","\n","    # Actualizar los componentes de la URL\n","    parsed_url = parsed_url._replace(path=new_path, query=new_query)\n","\n","    # Generar la URL formateada\n","    formatted_url = urlunparse(parsed_url)\n","\n","    return formatted_url\n","\n","url = \"https://drive.google.com/file/d/1HwnaNu0rOYNKd8_BkqB0MXQhozCyAe4U/view?usp=sharing\" #@param {type: 'string'}\n","print(\"Creando acceso directo...\")\n","\n","# Ejemplo de uso\n","url = format_google_drive_url(url)\n","print(url)\n","\n","crear_acceso_directo(url)\n","\n","while not os.path.exists(\"/content/drive/MyDrive/temporalmodels\"):\n","  time.sleep(1)\n","\n","if os.path.exists(\"/content/tempfolder\"):\n","  shutil.rmtree(\"/content/tempfolder\")\n","if os.path.exists(\"/content/Models\"):\n","  shutil.rmtree(\"/content/Models\")\n","\n","os.mkdir(\"/content/tempfolder\")\n","os.mkdir(\"/content/Models\")\n","print(\"Comprimiendo archivo (Esto puede tomar unos minutos)...\")\n","#Comprimir el acceso directo en /content/tempfolder/xxx.zip\n","shutil.make_archive(f\"/content/tempfolder/xxx\", \"zip\", \"/content/drive/MyDrive/temporalmodels\") \n","print(f\"Copiando a /content/Models...\")\n","#Descomprimir el archivo /content/tempfolder/xxx.zip en /content/Models/\n","shutil.unpack_archive(f\"/content/tempfolder/xxx.zip\", f\"/content/Models\")\n","\n","!rm -r /content/drive/MyDrive/Models\n","!rm -r /content/drive/MyDrive/temporalmodels\n","\n","# Obtener una lista de todos los archivos en el directorio\n","models = os.listdir(\"/content/Models\")\n","models_zip = [archivo for archivo in models if archivo.endswith(\".zip\")]\n","\n","for MODELNAME in models_zip:\n","  print(\"Cargando modelo...\")\n","  MODELNAME = MODELNAME.replace(\".zip\",\"\")\n","  \n","  # Directorio donde se descomprimió el archivo\n","  dest_path = os.path.join(\"/content/RVC/logs/\", MODELNAME)\n","  if os.path.exists(dest_path):\n","    # Si el archivo ya existe, eliminarlo\n","    shutil.rmtree(dest_path)\n","  !mkdir -p $dest_path\n","\n","  zip_file = os.path.join('/content/Models', MODELNAME + \".zip\")\n","  unzipped_dir = os.path.join(\"/content/unzips\", MODELNAME)\n","\n","  # Eliminar el directorio de destino si ya existe\n","  if os.path.exists(unzipped_dir):\n","    shutil.rmtree(unzipped_dir)\n","  # Descomprimir el archivo ZIP utilizando el nombre MODELNAME\n","  shutil.unpack_archive(zip_file, extract_dir=\"/content/unzips/\" +  MODELNAME, format='zip')\n","\n","  # Directorio donde se moverán los folders\n","  logs_dir = os.path.join('/content/RVC/logs', MODELNAME)\n","  weights_dir = '/content/RVC/weights'\n","  logs_folders = ['0_gt_wavs','1_16k_wavs','2a_f0','2b-f0nsf','3_feature256']\n","\n","  index_file = False\n","  model_file = False\n","  D_file = False\n","  G_file = False\n","\n","  model_name = MODELNAME\n","   # Mover el archivo D, G y added_*.index\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    for item in files:\n","      item_path = os.path.join(path, item)\n","      if not 'G_' in item and not 'D_' in item and item.endswith('.pth'):\n","        model_file = True\n","        model_name = item.replace(\".pth\",\"\")\n","        shutil.rmtree(logs_dir)\n","        logs_dir = f\"/content/RVC/logs/{model_name}\"\n","        os.mkdir(logs_dir)\n","        if not os.path.exists(weights_dir):\n","          os.mkdir(weights_dir)\n","        if os.path.exists(os.path.join(weights_dir, item)):\n","          os.remove(os.path.join(weights_dir, item))  \n","        if os.path.exists(item_path):\n","          shutil.move(item_path, weights_dir)\n","\n","  # Mover el model.pth y renombrar folder\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    for item in files:\n","      item_path = os.path.join(path, item)\n","      if item.startswith('added_') and item.endswith('.index'):\n","        index_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if 'D_' in item and item.endswith('.pth'):\n","        D_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if 'G_' in item and item.endswith('.pth'):\n","        G_file = True\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","      if item.startswith('total_fea.npy'):\n","        if os.path.exists(item_path):\n","          shutil.move(item_path, logs_dir)\n","          \n","  # Mover todos los folders excepto 'eval'\n","  for path, subdirs, files in os.walk(unzipped_dir):\n","    for folder in subdirs:\n","      if folder in logs_folders:\n","        item_path = os.path.join(path, folder)\n","        shutil.move(item_path, logs_dir)\n","\n","\n","  #!rm -r /content/RVC/logs/{MODELNAME}\n","  !rm -r /content/unzips/\n","  !rm -r /content/zips/\n","\n","  clear_output()\n","  display(success)\n","\n","  if model_file:\n","    if index_file:\n","      print(\"El modelo funciona para inferencia, y tiene el archivo .index\")\n","    else:\n","      print(\"El modelo funciona para inferencia, pero no tiene el archivo .index\")\n","  if D_file and G_file:\n","    print(\"El modelo puede ser reentrenado.\")\n","\n","!rm -r /content/Models\n","!rm -r /content/tempfolder"],"metadata":{"id":"bjcfXcgCtvi_","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color='#018ada'>Interfaz de gradio</font>\n","import os\n","import threading\n","import time\n","import shutil\n","import hashlib\n","# from pydrive.auth import GoogleAuth\n","# from pydrive.drive import GoogleDrive\n","# from google.colab import auth\n","# from google.colab import drive\n","# from oauth2client.client import GoogleCredentials\n","# auth.authenticate_user()\n","# gauth = GoogleAuth()\n","# gauth.credentials = GoogleCredentials.get_application_default()\n","# gdrive = GoogleDrive(gauth)\n","\n","%cd /content/RVC\n","if not os.path.exists(\"/content/RVC/weights\"):\n","  os.mkdir(\"/content/RVC/weights\")\n","\n","GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/RVC_Backup' # cambiar a tu ubicacion de drive\n","LOGS_FOLDER = '/content/RVC/logs'\n","WEIGHTS_FOLDER = '/content/RVC/weights'\n","#@markdown # Opciones generales\n","#@markdown ¿Quieres entrenar un modelo o hacer inferencia?\n","modo_entrenamiento = True #@param{type: 'boolean'}\n","#@markdown Si google colab se desconectó mientras se entrenaba el modelo, puedes cargar la última copia de seguridad guardada en tu Drive\n","cargar_backup = False #@param{type: 'boolean'}\n","#@markdown # Entrenamiento\n","#@markdown Si deseas crear un backup automatico durante el entrenamiento\n","crear_backup_automatico = False #@param{type: 'boolean'}\n","#@markdown Para obtener estadisticas de como va el entrenamiento\n","usar_tensorboard = False #@param{type: 'boolean'}\n","\n","# Buscar modelos guardados en drive y restaurarlos en el folder /rvc\n","def import_google_drive_backup():\n","    print(\"Importando backup de Google Drive...\")\n","    weights_exist = False\n","\n","    for root, dirs, files in os.walk(GOOGLE_DRIVE_PATH):\n","        for filename in files:\n","            filepath = os.path.join(root, filename)\n","            # Si existen archivos de backups meterlos en la carpeta rvc/logs con metadatos\n","            if os.path.isfile(filepath) and not filepath.startswith(os.path.join(GOOGLE_DRIVE_PATH, 'weights')):\n","                backup_filepath = os.path.join(LOGS_FOLDER, os.path.relpath(filepath, GOOGLE_DRIVE_PATH))\n","                backup_folderpath = os.path.dirname(backup_filepath)\n","                if not os.path.exists(backup_folderpath):\n","                    os.makedirs(backup_folderpath)\n","                    print(f'Se ha creado backup del folder: {backup_folderpath}', flush=True)\n","                shutil.copy2(filepath, backup_filepath) # Copiar archivo con metadatos\n","                print(f'Importado archivo de backup: {filename}')\n","            # Si el archivo actual pertenece a pesos entonces meterlo a rvc/weights con metadatos\n","            elif filepath.startswith(os.path.join(GOOGLE_DRIVE_PATH, 'weights')) and filename.endswith('.pth'):\n","                weights_exist = True\n","                weights_filepath = os.path.join(WEIGHTS_FOLDER, os.path.relpath(filepath, os.path.join(GOOGLE_DRIVE_PATH, 'weights')))\n","                weights_folderpath = os.path.dirname(weights_filepath)\n","                if not os.path.exists(weights_folderpath):\n","                    os.makedirs(weights_folderpath)\n","                    print(f'Folder weights creado: {weights_folderpath}', flush=True)\n","                shutil.copy2(filepath, weights_filepath) # Copiar los metadatos del archivo\n","                print(f'Archivo importado desde weights: {filename}')\n","\n","    if weights_exist:\n","        print(\"Pesos copiados del backup de Google Drive a la carpeta de pesos local.\")\n","    else:\n","        print(\"No se encontraron pesos en el backup de Google Drive.\")\n","    print(\"Importación del backup completado.\")\n","\n","# Importar modelos antes de iniciar el servidor\n","if cargar_backup:\n","  import_google_drive_backup()\n","\n","def empezar_servidor():\n","    %cd /content/RVC\n","    if usar_tensorboard:\n","      %load_ext tensorboard\n","      %tensorboard --logdir /content/RVC/logs\n","    !mkdir -p /content/RVC/audios\n","    !python3 infer-web.py --colab --pycmd python3\n","\n","\n","def copiar_folder_pesos_a_drive():\n","    # Verificar si no existe el folder weights en el folder backup\n","    destination_folder = os.path.join(GOOGLE_DRIVE_PATH, 'weights')\n","    if not os.path.exists(destination_folder):\n","        os.makedirs(destination_folder)\n","\n","    # \n","    num_copied = 0\n","    # Copiar los archivos .pth qsi aún no existen en drive\n","    for filename in os.listdir(WEIGHTS_FOLDER):\n","        if filename.endswith('.pth'):\n","            source_file = os.path.join(WEIGHTS_FOLDER, filename)\n","            destination_file = os.path.join(destination_folder, filename)\n","            if not os.path.exists(destination_file):\n","                shutil.copy2(source_file, destination_file)\n","                num_copied += 1\n","                print(f\"{filename} copiado a Google Drive!\")\n","    \n","    if num_copied == 0:\n","        print(\"No se encontraron nuevos modelos terminados para copiar.\")\n","    else:\n","        print(f\"¡Terminó de copiar {num_copied} archivos a Google Drive!\")\n","\n","\n","def backup_files():\n","    print(\"Iniciando bucle de copia de seguridad...\")\n","    last_backup_timestamps_path = os.path.join(LOGS_FOLDER, 'last_backup_timestamps.txt')\n","    fully_updated = False  # booleano para rastrear si todos los archivos están actualizados\n","    try:\n","        with open(last_backup_timestamps_path, 'r') as f:\n","            last_backup_timestamps = dict(line.strip().split(':') for line in f)\n","    except:\n","        last_backup_timestamps = {}\n","    while True:\n","        updated = False # marca para verificar si se actualizó algún archivo\n","        # Recorrer /content/RVC\n","        for root, dirs, files in os.walk(LOGS_FOLDER):\n","            for filename in files:\n","                if filename != 'last_backup_timestamps.txt':\n","                    filepath = os.path.join(root, filename)\n","                    if os.path.isfile(filepath):\n","                        backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n","                        backup_folderpath = os.path.dirname(backup_filepath)\n","                        if not os.path.exists(backup_folderpath):\n","                            os.makedirs(backup_folderpath)\n","                            print(f'Se ha creado un folder backup de: {backup_folderpath}', flush=True)\n","                        # se comprueba si el archivo ha cambiado desde el ultimo backup\n","                        last_backup_timestamp = last_backup_timestamps.get(filepath)\n","                        current_timestamp = os.path.getmtime(filepath)\n","                        if last_backup_timestamp is None or float(last_backup_timestamp) < current_timestamp:\n","                            shutil.copy2(filepath, backup_filepath) # copiar archivo con metadata\n","                            last_backup_timestamps[filepath] = str(current_timestamp) # actualizar las marcas de tiempo\n","                            if last_backup_timestamp is None:\n","                              extension = \"dsadsa.wav.pth\".split(\".\")[-1]\n","                              if extension != \"npy\" and extension != \"pt\":\n","                                print(f'Se ha creado backup de: {filename}')\n","                            else:\n","                              extension = \"dsadsa.wav.pth\".split(\".\")[-1]\n","                              if extension != \"npy\" and extension != \"pt\":\n","                                print(f'Se ha actualizado el backup de: {filename}')\n","                            updated = True\n","                            fully_updated = False  # si un archivo se actualiza, todos los archivos no están actualizados\n","\n","        # verificar si se eliminaron archivos en Colab y eliminarlos del backup\n","        for filepath in list(last_backup_timestamps.keys()):\n","            if not os.path.exists(filepath):\n","                backup_filepath = os.path.join(GOOGLE_DRIVE_PATH, os.path.relpath(filepath, LOGS_FOLDER))\n","                if os.path.exists(backup_filepath):\n","                    os.remove(backup_filepath)\n","                    print(f'Deleted file: {filepath}')\n","                del last_backup_timestamps[filepath]\n","                updated = True\n","                fully_updated = False  # si se elimina un archivo, todos los archivos no están actualizados\n","        if not updated and not fully_updated:\n","            print(\"Los archivos están actualizados.\")\n","            fully_updated = True  # si todos los archivos están actualizados, establecer el booleano en True\n","            copiar_folder_pesos_a_drive()\n","            sleep_time = 30\n","        else:\n","            sleep_time = 1\n","        with open(last_backup_timestamps_path, 'w') as f:\n","            for filepath, timestamp in last_backup_timestamps.items():\n","                f.write(f'{filepath}:{timestamp}\\n')\n","        time.sleep(sleep_time) # esperar 30 segundos antes de verificar nuevamente, o 1s si no está completamente actualizado para acelerar los backup\n","\n","if modo_entrenamiento:\n","  if crear_backup_automatico:\n","    # Empezar el servidor en un hilo separadp\n","    web_server_thread = threading.Thread(target=empezar_servidor)\n","    web_server_thread.start()\n","    \n","    # Ejecutar el ciclo de backup en el hilo principal\n","    backup_files()\n","  else:\n","    empezar_servidor()\n","else:\n","  !python3 /content/RVC/easy-infer.py --colab --pycmd python3"],"metadata":{"id":"7vh6vphDwO0b","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title <font color='#018ada'>Paso 5. Guardar el modelo</font>\n","#@markdown ###Selecciona tus preferencias de guardado. No olvides pausar el paso 3 antes de continuar con este.\n","#@markdown - Guardar todo - feature extraction (más de 1GB)\n","#@markdown <br> (Si quieres reentrenar tu modelo sin usar extracción de caracteristicas nuevo)\n","#@markdown - Guardar modelo de voz + archivos D, G files (1.02GB)\n","#@markdown - Guardar solo modelo de voz (84MB)\n","\n","\n","#@markdown ### Introduce el nombre que entrenaste.\n","NOMBRE_MODELO = \"AnuelAAv2\"  #@param {type:\"string\"}\n","TIPO_GUARDADO = \"guardar_voz\" #@param [\"guardar_todo\", \"guardar_voz_D_G\", \"guardar_voz\"]\n","%cd /content\n","#print(NOMBRE_MODELO)\n","import shutil, os\n","\n","if os.path.exists('/content/zips'):\n","  shutil.rmtree('/content/zips')\n","\n","src = os.path.join(\"/content/RVC/logs\",NOMBRE_MODELO)\n","dst = os.path.join(\"/content/zips/\",NOMBRE_MODELO)\n","\n","if TIPO_GUARDADO == \"guardar_todo\":\n","  shutil.copytree(src, dst)\n","  !cp /content/RVC/weights/{NOMBRE_MODELO}.pth /content/zips/{NOMBRE_MODELO}/\n","if TIPO_GUARDADO == \"guardar_voz_D_G\":\n","  !mkdir -p /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/logs/{NOMBRE_MODELO}/D_*.pth /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/logs/{NOMBRE_MODELO}/G_*.pth /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/logs/{NOMBRE_MODELO}/added_*.index /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/weights/{NOMBRE_MODELO}.pth /content/zips/{NOMBRE_MODELO}/\n","if TIPO_GUARDADO == \"guardar_voz\":\n","  !mkdir -p /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/logs/{NOMBRE_MODELO}/added_*.index /content/zips/{NOMBRE_MODELO}/\n","  !cp /content/RVC/weights/{NOMBRE_MODELO}.pth /content/zips/{NOMBRE_MODELO}/\n","\n","\n","\n","!mkdir -p /content/drive/MyDrive/RVC/\n","\n","%cd /content/zips\n","!zip -r {NOMBRE_MODELO}.zip {NOMBRE_MODELO}\n","shutil.move(f'/content/zips/{NOMBRE_MODELO}.zip',f'/content/drive/MyDrive/RVC/{NOMBRE_MODELO}.zip')\n","%cd /content\n","shutil.rmtree(\"/content/zips\")\n","clear_output()\n","display(success)"],"metadata":{"cellView":"form","id":"POuTKzt8gZmF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#<font color='gray'>Cosas extra (Utilidades)<font color='red'>"],"metadata":{"id":"p9SHghdUw2O_"}},{"cell_type":"code","source":["#@title Creador de DATASETs\n","#@markdown Solo carga los archivos acapella en formato .wav en la carpeta **EasyDataset** (asegúrese de que sea material de buena calidad, por favor)\n","#@markdown No uses espacios, símbolos extraños ni nada por el estilo.\n","if not \"pydub_installed\" in locals():\n","  !pip install pydub --quiet\n","  pydub_installed=True\n","\n","from pydub import AudioSegment\n","import os, shutil, wave\n","from google.colab import files\n","eliminar_automaticamente_acapella_original=True#@param {type:\"boolean\"}\n","\n","guardar_en_drive=True#@param {type:\"boolean\"}\n","#@markdown Selecciona el nombre de tu DATASET (lo usarás más tarde en la interfaz)\n","nombre_del_dataset=''#@param {type:\"string\"}\n","if not \"installed_pydub\" in locals():\n","  !pip install pydub --quiet\n","\n","if not os.path.exists('/content/EasyDataset'):\n","  !mkdir -p /content/EasyDataset\n","  os.chdir('/content/EasyDataset')\n","  print(\"Upload some files.\")\n","  uploaded = files.upload()\n","else:\n","  os.chdir('/content/EasyDataset')\n","  if not os.listdir():\n","    print(\"Upload some files.\")\n","    uploaded = files.upload()\n","\n","for filename in os.listdir():\n","    if filename.endswith(\".wav\"):\n","        sound = AudioSegment.from_wav(filename)\n","        sound = sound.set_channels(1)\n","        new_filename = filename\n","        sound.export('mono_'+new_filename, format=\"wav\")\n","        os.remove(filename)\n","\n","# define the length of each clip in seconds\n","clip_length = 10\n","# iterate over all .wav files in the current directory\n","for filename in os.listdir():\n","    if not filename.endswith('.wav'):\n","        continue\n","    # open the WAV file and get the sample rate\n","    wav_file = wave.open(filename, 'rb')\n","    sample_rate = wav_file.getframerate()\n","    # calculate the number of frames in each clip\n","    clip_frames = clip_length * sample_rate\n","    # iterate over each clip and write it to a new file\n","    for i in range(int(wav_file.getnframes() / clip_frames) + 1):\n","        clip_name = f\"{filename.split('.')[0]}_{i+1}.wav\"\n","        clip_path = 'split_'+clip_name\n","        clip_start = i * clip_frames\n","        clip_end = min((i+1) * clip_frames, wav_file.getnframes())\n","\n","        # write the clip to a new file\n","        with wave.open(clip_path, 'wb') as clip_file:\n","            clip_file.setparams(wav_file.getparams())\n","            clip_file.writeframes(wav_file.readframes(clip_end - clip_start))\n","    # close the original file\n","    wav_file.close()\n","    os.remove(filename)\n","!mkdir -p /content/dataset/{nombre_del_dataset}\n","for everything in os.listdir('/content/EasyDataset'):\n","  shutil.move(everything, f'/content/dataset/{nombre_del_dataset}')\n","!ls -a /content/dataset/\n","!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*\n","os.chdir(f'/content/dataset')\n","print(f\"Your dataset has been saved to: /content/dataset/{nombre_del_dataset}\")\n","if eliminar_automaticamente_acapella_original:\n","  shutil.rmtree('/content/EasyDataset')\n","  !mkdir -p /content/EasyDataset\n","if guardar_en_drive:\n","  !zip -r {nombre_del_dataset}.zip {nombre_del_dataset}\n","  shutil.move(f'/content/dataset/{nombre_del_dataset}.zip','/content/drive/MyDrive/dataset')\n","os.chdir('/content')"],"metadata":{"cellView":"form","id":"dF8MCnjxldPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Analizador de modelos.\n","#@markdown Usa esto para averiguar para cuántas épocas se entrenó tu modelo o la frecuencia de muestreo.\n","import torch, os\n","#@markdown Pon la ruta exacta de tu modelo (el archivo de peso).\n","RUTA_DEL_MODELO=''#@param {type:\"string\"}\n","model_params = torch.load(RUTA_DEL_MODELO)\n","param_names = list(model_params.keys())\n","#print(param_names)\n","for key in model_params.keys():\n","    if key == 'info':\n","       print('Epochs: '+model_params[str(key)])\n","    if key == 'sr':\n","       print('Sample Rate: '+model_params[str(key)])"],"metadata":{"id":"XGgTjE5r7ZF_","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Descargar dataset desde un enlace\n","#@markdown **Imporante:** Debe ser un enlace compartido\n","!pip install gdown\n","import gdown\n","\n","url = \"\"  #@param {type:\"string\"}\n","gdown.download(url, output=\"/content/drive/MyDrive/dataset/Tzuyu7.zip\", quiet=True, fuzzy=True)\n"],"metadata":{"cellView":"form","id":"ooUTD7Dkkxlj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Lista de módelos:\n","##Estaré publicando algunos modelos aquí para facilitar el acceso. Copia el enlace y pégalo en el paso 2 (escribe el nombre del artista)\n","\n","**jungkook:** https://drive.google.com/file/d/1i5CMlcnKfVEpzD5wvwjWytrwT2fT74g6/view?usp=share_link\n","\n","**BENEE:** https://drive.google.com/file/d/1nuUVTqg1_lja7JFctjd18W9hQ7rk7aDZ/view?usp=share_link\n","\n","**shiloh:** https://drive.google.com/file/d/12nk3OOEVdhWB6eBNYN5Gw0wbifIYx_fF/view?usp=share_link\n","\n","**Bad Bunny (1000):** https://drive.google.com/file/d/1xQ4vmMnLCEBkLbq5xRF9Qpr6LJLcldEJ/view?usp=share_link\n","\n","**Lisa - Blackpink (900):** https://drive.google.com/file/d/1HdadjSWbxkgJhqj4BpMPskslZ0y3CWuq/view?usp=share_link\n","\n","**Michael Jackson (1000):** https://mega.nz/file/wD0zTKYC#dovBmijBPKew_m3m-l0enihYFiVv77bxa371ObhnDuA\n","\n","**Camila Cabello (600):** https://mega.nz/file/2xtl1azK#ZbDP1OvP3sZLqeLn_TNFtIN1bF2fOl2bBQJznT8u3Fw\n","\n","**Eminem (1000):** https://mega.nz/file/fiZRlABJ#6uHSSeMCAtLesA9wJ6iHOh41txW08nwoed_NDWZmwcw\n","\n","**Adele (400):** https://drive.google.com/file/d/1454sbUV0We23y9a7QkoTXfY52HXorTCV/view?usp=share_link\n","\n","Inference ONLY colab:\n","\n","https://colab.research.google.com/drive/1r4IRL0UA7JEoZ0ZK8PKfMyTIBHKpyhcw?usp=sharing"],"metadata":{"id":"Y13Eh9r_g8f-"}}]}